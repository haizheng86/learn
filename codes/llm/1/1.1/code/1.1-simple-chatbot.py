# ai_assistant.py
# Python 3.9+ ç‰ˆæœ¬
# ä¾èµ–: pip install openai python-dotenv streamlit streamlit-chat

import os
import json
import time
from datetime import datetime
import streamlit as st
import openai
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Python AIåŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åº”ç”¨æ ‡é¢˜å’ŒCSSæ ·å¼
st.markdown("""
<style>
    .main-header {text-align: center; font-size: 2.5rem; margin-bottom: 1rem;}
    .subheader {text-align: center; font-size: 1.2rem; margin-bottom: 2rem; color: #888;}
    .chat-message {padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem; line-height: 1.5;}
    .user-message {background-color: #e6f7ff; border-left: 5px solid #1890ff;}
    .assistant-message {background-color: #f6ffed; border-left: 5px solid #52c41a;}
    .error-message {background-color: #fff2f0; border-left: 5px solid #ff4d4f;}
    .info-box {background-color: #f0f2f5; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;}
    .footer {text-align: center; margin-top: 2rem; color: #888; font-size: 0.8rem;}
    .stButton>button {width: 100%;}
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">Python AIåŠ©æ‰‹</h1>', unsafe_allow_html=True)
st.markdown('<p class="subheader">åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ</p>', unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = datetime.now().strftime("%Y%m%d_%H%M%S")

if "settings" not in st.session_state:
    st.session_state.settings = {
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "max_tokens": 1000,
        "stream": True
    }

# è·å–APIå¯†é’¥
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    api_key = st.sidebar.text_input("OpenAI APIå¯†é’¥", type="password")
    if not api_key:
        st.sidebar.error("è¯·è¾“å…¥æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        st.sidebar.info("å¦‚ä½•è·å–APIå¯†é’¥ï¼š\n1. è®¿é—® [OpenAIç½‘ç«™](https://platform.openai.com/)\n2. æ³¨å†Œæˆ–ç™»å½•è´¦å·\n3. åœ¨ä¸ªäººè®¾ç½®ä¸­æ‰¾åˆ°'API Keys'é€‰é¡¹\n4. åˆ›å»ºæ–°çš„å¯†é’¥")
        st.stop()

# è®¾ç½®OpenAIå®¢æˆ·ç«¯
openai.api_key = api_key

# ä¾§è¾¹æ  - è®¾ç½®å’Œä¼šè¯ç®¡ç†
with st.sidebar:
    st.header("ğŸ› ï¸ è®¾ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    model_options = ["gpt-3.5-turbo", "gpt-4", "gpt-3.5-turbo-16k"]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_options, index=model_options.index(st.session_state.settings["model"]))
    st.session_state.settings["model"] = selected_model
    
    # å‚æ•°è°ƒæ•´
    st.session_state.settings["temperature"] = st.slider("æ¸©åº¦ (åˆ›é€ æ€§)", 0.0, 1.0, st.session_state.settings["temperature"], 0.1,
                                                       help="è¾ƒé«˜çš„å€¼ä½¿è¾“å‡ºæ›´åŠ éšæœºå’Œåˆ›é€ æ€§ï¼Œè¾ƒä½çš„å€¼ä½¿è¾“å‡ºæ›´åŠ ç¡®å®šå’Œé›†ä¸­")
    st.session_state.settings["max_tokens"] = st.slider("æœ€å¤§å›å¤é•¿åº¦", 100, 4000, st.session_state.settings["max_tokens"], 100,
                                                     help="æ§åˆ¶AIå›å¤çš„æœ€å¤§é•¿åº¦")
    
    st.session_state.settings["stream"] = st.checkbox("æµå¼è¾“å‡º", st.session_state.settings["stream"],
                                                  help="å¯ç”¨åå¯ä»¥çœ‹åˆ°AIé€å­—å›å¤")
    
    st.divider()
    st.header("ğŸ’¾ ä¼šè¯ç®¡ç†")
    
    # æ–°å»ºä¼šè¯
    if st.button("â• æ–°å»ºä¼šè¯"):
        st.session_state.messages = []
        st.session_state.current_conversation_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.success("å·²åˆ›å»ºæ–°ä¼šè¯")
        st.experimental_rerun()
    
    # ä¿å­˜å½“å‰ä¼šè¯
    if st.button("ğŸ’¾ ä¿å­˜å½“å‰ä¼šè¯") and st.session_state.messages:
        try:
            conversation_data = {
                "id": st.session_state.current_conversation_id,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "messages": st.session_state.messages
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            st.session_state.conversation_history.append(conversation_data)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            os.makedirs("conversations", exist_ok=True)
            with open(f"conversations/{st.session_state.current_conversation_id}.json", "w") as f:
                json.dump(conversation_data, f, indent=2)
            
            st.success("ä¼šè¯å·²ä¿å­˜")
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºå†å²ä¼šè¯
    if st.session_state.conversation_history:
        st.divider()
        st.subheader("å†å²ä¼šè¯")
        for conv in reversed(st.session_state.conversation_history):
            if st.button(f"{conv['timestamp']} ({len(conv['messages'])}æ¡æ¶ˆæ¯)", key=f"history_{conv['id']}"):
                st.session_state.messages = conv['messages']
                st.session_state.current_conversation_id = conv['id']
                st.experimental_rerun()

# ä¸»ç•Œé¢ - èŠå¤©åŒº
chat_container = st.container()

with chat_container:
    # æ˜¾ç¤ºèŠå¤©å†å²
    for idx, message in enumerate(st.session_state.messages):
        role = message["role"]
        content = message["content"]
        
        if role == "user":
            st.markdown(f'<div class="chat-message user-message"><strong>ä½ :</strong> {content}</div>', unsafe_allow_html=True)
        elif role == "assistant":
            st.markdown(f'<div class="chat-message assistant-message"><strong>AIåŠ©æ‰‹:</strong> {content}</div>', unsafe_allow_html=True)
        elif role == "system":
            continue
        elif role == "error":
            st.markdown(f'<div class="chat-message error-message"><strong>é”™è¯¯:</strong> {content}</div>', unsafe_allow_html=True)

# è¾“å…¥åŒº
with st.container():
    col1, col2 = st.columns([5, 1])
    
    with col1:
        user_input = st.text_area("åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜...", height=100, key="user_input")
    
    with col2:
        st.write("")
        st.write("")
        send_button = st.button("å‘é€", use_container_width=True)
    
    # è¾…åŠ©åŠŸèƒ½åŒº
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ‘‹ è‡ªæˆ‘ä»‹ç»", use_container_width=True):
            user_input = "è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
            send_button = True
    
    with col2:
        if st.button("ğŸ“š Pythonå­¦ä¹ è·¯å¾„", use_container_width=True):
            user_input = "ç»™æˆ‘æ¨èä¸€ä¸ªPythonä»å…¥é—¨åˆ°ç²¾é€šçš„å­¦ä¹ è·¯å¾„"
            send_button = True
    
    with col3:
        if st.button("ğŸ§  AIå‘å±•è¶‹åŠ¿", use_container_width=True):
            user_input = "è¯·åˆ†æä¸€ä¸‹2025å¹´AIé¢†åŸŸçš„ä¸»è¦å‘å±•è¶‹åŠ¿"
            send_button = True

# å¤„ç†ç”¨æˆ·è¾“å…¥
if send_button and user_input:
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # åˆ›å»ºå®Œæ•´çš„æ¶ˆæ¯å†å²
    messages_for_api = []
    
    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼Œå¦‚æœæ²¡æœ‰çš„è¯
    if not any(msg["role"] == "system" for msg in st.session_state.messages):
        system_message = {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œç”±Pythonæ‰“é€ ã€‚ä½ å…·æœ‰å¹¿æ³›çš„çŸ¥è¯†ï¼Œå°¤å…¶æ“…é•¿Pythonç¼–ç¨‹ã€æ•°æ®ç§‘å­¦å’Œäººå·¥æ™ºèƒ½ç›¸å…³è¯é¢˜ã€‚"
                       "è¯·æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ï¼Œå¹¶åœ¨é€‚å½“çš„æƒ…å†µä¸‹æä¾›ä»£ç ç¤ºä¾‹ã€‚"
                       "ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­æ°”ï¼Œé¿å…ç”Ÿæˆæœ‰å®³æˆ–ä¸é€‚å½“çš„å†…å®¹ã€‚"
        }
        messages_for_api.append(system_message)
    
    # æ·»åŠ æ‰€æœ‰èŠå¤©å†å²
    for msg in st.session_state.messages:
        if msg["role"] != "error":  # è·³è¿‡é”™è¯¯æ¶ˆæ¯
            messages_for_api.append({"role": msg["role"], "content": msg["content"]})
    
    # æ˜¾ç¤ºæ€è€ƒä¸­çš„çŠ¶æ€
    with st.status("AIåŠ©æ‰‹æ­£åœ¨æ€è€ƒ...") as status:
        try:
            if st.session_state.settings["stream"]:
                # æµå¼å“åº”
                response_container = st.empty()
                full_response = ""
                
                # è°ƒç”¨API
                response = openai.ChatCompletion.create(
                    model=st.session_state.settings["model"],
                    messages=messages_for_api,
                    temperature=st.session_state.settings["temperature"],
                    max_tokens=st.session_state.settings["max_tokens"],
                    stream=True
                )
                
                # é€æ­¥å¤„ç†æµå¼å“åº”
                for chunk in response:
                    if hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                        content_chunk = chunk.choices[0].delta.get("content", "")
                        full_response += content_chunk
                        response_container.markdown(f"<div class='chat-message assistant-message'><strong>AIåŠ©æ‰‹:</strong> {full_response}â–Œ</div>", unsafe_allow_html=True)
                
                # æ·»åŠ æœ€ç»ˆå“åº”åˆ°ä¼šè¯
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                status.update(label="å›ç­”å®Œæˆï¼", state="complete")
                
            else:
                # éæµå¼å“åº”
                response = openai.ChatCompletion.create(
                    model=st.session_state.settings["model"],
                    messages=messages_for_api,
                    temperature=st.session_state.settings["temperature"],
                    max_tokens=st.session_state.settings["max_tokens"],
                    stream=False
                )
                
                # æå–å“åº”å†…å®¹
                assistant_response = response.choices[0].message.content
                
                # æ·»åŠ åˆ°ä¼šè¯
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})
                status.update(label="å›ç­”å®Œæˆï¼", state="complete")
        
        except Exception as e:
            # å¤„ç†é”™è¯¯
            error_message = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            st.session_state.messages.append({"role": "error", "content": error_message})
            status.update(label="å‡ºé”™äº†ï¼", state="error")
    
    # æ¸…ç©ºè¾“å…¥æ¡†å¹¶åˆ·æ–°é¡µé¢
    st.experimental_rerun()

# é¡µè„š
st.markdown('<div class="footer">é€šè¿‡Pythonå’ŒOpenAI APIæ„å»ºçš„AIåŠ©æ‰‹èŠå¤©æœºå™¨äºº | åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹</div>', unsafe_allow_html=True)

# æ·»åŠ ä½¿ç”¨è¯´æ˜
with st.expander("ğŸ“‹ ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    ### å¦‚ä½•ä½¿ç”¨è¿™ä¸ªAIåŠ©æ‰‹
    
    1. **è¾“å…¥é—®é¢˜**ï¼šåœ¨åº•éƒ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤
    2. **å‘é€æ¶ˆæ¯**ï¼šç‚¹å‡»"å‘é€"æŒ‰é’®æˆ–ä½¿ç”¨å¿«æ·æŒ‰é’®æé—®é¢„è®¾é—®é¢˜
    3. **æŸ¥çœ‹å›ç­”**ï¼šAIåŠ©æ‰‹å°†ç”Ÿæˆå›ç­”å¹¶æ˜¾ç¤ºåœ¨èŠå¤©åŒº
    4. **è°ƒæ•´è®¾ç½®**ï¼šåœ¨ä¾§è¾¹æ ä¸­å¯ä»¥æ›´æ”¹æ¨¡å‹å’Œå‚æ•°è®¾ç½®
    5. **ä¼šè¯ç®¡ç†**ï¼šå¯ä»¥ä¿å­˜å½“å‰ä¼šè¯ï¼Œåˆ›å»ºæ–°ä¼šè¯ï¼Œæˆ–åŠ è½½å†å²ä¼šè¯
    
    ### åŠŸèƒ½ç‰¹ç‚¹
    
    - **æµå¼è¾“å‡º**ï¼šå®æ—¶çœ‹åˆ°AIçš„å›ç­”è¿‡ç¨‹
    - **ä¼šè¯ä¿å­˜**ï¼šä¿å­˜é‡è¦çš„å¯¹è¯å†…å®¹ä»¥ä¾¿æ—¥åæŸ¥çœ‹
    - **è‡ªå®šä¹‰è®¾ç½®**ï¼šæ ¹æ®éœ€è¦è°ƒæ•´AIçš„åˆ›é€ æ€§å’Œå›å¤é•¿åº¦
    - **å¤šç§æ¨¡å‹**ï¼šé€‰æ‹©ä¸åŒçš„AIæ¨¡å‹ä»¥æ»¡è¶³ä¸åŒéœ€æ±‚
    
    ### æœ€ä½³å®è·µ
    
    - æå‡ºæ˜ç¡®ã€å…·ä½“çš„é—®é¢˜ä¼šå¾—åˆ°æ›´å‡†ç¡®çš„å›ç­”
    - å¯¹äºå¤æ‚é—®é¢˜ï¼Œå¯ä»¥åˆ†æ­¥éª¤æé—®
    - è°ƒä½æ¸©åº¦å‚æ•°å¯ä»¥è·å¾—æ›´ç¡®å®šã€å‡†ç¡®çš„å›ç­”
    - è°ƒé«˜æ¸©åº¦å‚æ•°å¯ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„å›ç­”
    """)

# åˆ›å»ºä¸€ä¸ªå¸®åŠ©æ–‡æ¡£
with st.expander("â“ å¸¸è§é—®é¢˜ (FAQ)"):
    st.markdown("""
    ### å¸¸è§é—®é¢˜è§£ç­”
    
    **é—®ï¼šè¿™ä¸ªAIåŠ©æ‰‹èƒ½å›ç­”ä»€ä¹ˆç±»å‹çš„é—®é¢˜ï¼Ÿ**  
    ç­”ï¼šæœ¬åŠ©æ‰‹æ“…é•¿Pythonç¼–ç¨‹ã€æ•°æ®ç§‘å­¦ã€AIç­‰æŠ€æœ¯è¯é¢˜ï¼Œä½†ä¹Ÿèƒ½å›ç­”å¹¿æ³›çš„çŸ¥è¯†æ€§é—®é¢˜ã€‚
    
    **é—®ï¼šæˆ‘çš„å¯¹è¯å†…å®¹ä¼šè¢«ä¿å­˜åœ¨å“ªé‡Œï¼Ÿ**  
    ç­”ï¼šå¯¹è¯å†…å®¹ä¼šæš‚æ—¶ä¿å­˜åœ¨æ‚¨çš„æµè§ˆå™¨ä¼šè¯ä¸­ï¼Œå¦‚æœæ‚¨æ‰‹åŠ¨ä¿å­˜ä¼šè¯ï¼Œåˆ™ä¼šå­˜å‚¨åœ¨æœ¬åœ°çš„"conversations"æ–‡ä»¶å¤¹ä¸­ã€‚
    
    **é—®ï¼šå¦‚ä½•è·å–OpenAI APIå¯†é’¥ï¼Ÿ**  
    ç­”ï¼šæ‚¨éœ€è¦åœ¨OpenAIå®˜ç½‘(https://platform.openai.com/)æ³¨å†Œè´¦å·ï¼Œç„¶ååœ¨API Keyséƒ¨åˆ†åˆ›å»ºä¸€ä¸ªæ–°çš„å¯†é’¥ã€‚
    
    **é—®ï¼šä¸åŒçš„æ¨¡å‹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**  
    ç­”ï¼š
    - gpt-3.5-turboï¼šå¹³è¡¡äº†æ€§èƒ½å’Œæˆæœ¬ï¼Œé€‚åˆå¤§å¤šæ•°å¯¹è¯åœºæ™¯
    - gpt-4ï¼šæ›´å¼ºå¤§çš„ç†è§£èƒ½åŠ›å’Œç”Ÿæˆè´¨é‡ï¼Œä½†æˆæœ¬æ›´é«˜
    - gpt-3.5-turbo-16kï¼šä¸gpt-3.5-turboç±»ä¼¼ï¼Œä½†æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£
    
    **é—®ï¼šAPIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**  
    ç­”ï¼š
    1. æ£€æŸ¥æ‚¨çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®
    2. ç¡®è®¤æ‚¨çš„OpenAIè´¦æˆ·ä½™é¢å……è¶³
    3. å°è¯•æ›´æ¢æ¨¡å‹æˆ–å‡å°‘æœ€å¤§å›å¤é•¿åº¦
    4. æ‚¨å¯èƒ½è¾¾åˆ°äº†APIè°ƒç”¨é€Ÿç‡é™åˆ¶ï¼Œç¨ç­‰ç‰‡åˆ»å†è¯•
    """)


# pip install openai python-dotenv streamlit streamlit-chat
# åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® OPENAI_API_KEY=ä½ çš„å¯†é’¥
# åœ¨ç»ˆç«¯è¿è¡Œï¼šstreamlit run simple-chatbot.py